Set up

1. install requirements.txt and pip install git+https://github.com/openai/CLIP.git
2. download model from https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/official/detection/projects/vild/ViLD_demo.ipynb#scrollTo=qNQGKDBK3Mlc by running the first two cells and coppying content in image_path_v2 into save_models
3. use config/eval.yaml to set up model configuration
4. run demo.py 